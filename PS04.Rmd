---
title: "STAT/MATH 495: Problem Set 04"
author: "Luke Haggerty"
date: "2017-10-03"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 2
    collapsed: false
    smooth_scroll: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width=8, fig.height=4.5, message=FALSE)
set.seed(76)
```

# Collaboration

Please indicate who you collaborated with on this assignment: Leonard helped me with a couple coding questions I had. Jeff helped me with interpreting the Graphs.


# Load packages, data, model formulas

```{r, warning=FALSE}
library(tidyverse)
credit <- read_csv("http://www-bcf.usc.edu/~gareth/ISL/Credit.csv") %>%
  select(-X1) %>%
  mutate(ID = 1:n()) %>% 
  select(ID, Balance, Income, Limit, Rating, Age, Cards, Education)
```

You will train the following 7 models on `credit_train`...

```{r}
model1_formula <- as.formula("Balance ~ 1")
model2_formula <- as.formula("Balance ~ Income")
model3_formula <- as.formula("Balance ~ Income + Limit")
model4_formula <- as.formula("Balance ~ Income + Limit + Rating")
model5_formula <- as.formula("Balance ~ Income + Limit + Rating + Age")
model6_formula <- as.formula("Balance ~ Income + Limit + Rating + Age + Cards")
model7_formula <- as.formula("Balance ~ Income + Limit + Rating + Age + Cards + Education")
```

... where `credit_train` is defined below, along with `credit_test`.

```{r}
set.seed(79)
credit_train <- credit %>% 
  sample_n(20)
credit_test <- credit %>% 
  anti_join(credit_train, by="ID")
```


# RMSE vs number of coefficients

```{r, echo=TRUE, warning=FALSE, message=FALSE}
# Placeholder vectors of length 7. For now, I've filled them with arbitrary 
# values; you will fill these in
RMSE_train <- runif(n=7)
RMSE_test <- runif(n=7)


# Do your work here:
model_lm1 <- lm(model1_formula, data=credit_train)
model_lm2 <- lm(model2_formula, data=credit_train)
model_lm3 <- lm(model3_formula, data=credit_train)
model_lm4 <- lm(model4_formula, data=credit_train)
model_lm5 <- lm(model5_formula, data=credit_train)
model_lm6 <- lm(model6_formula, data=credit_train)
model_lm7 <- lm(model7_formula, data=credit_train)

sm1 <-summary(model_lm1)
rmse1 <- sqrt(mean(sm1$residuals^2))
RMSE_train[1] <- rmse1

sm2 <-summary(model_lm2)
rmse2 <- sqrt(mean(sm2$residuals^2))
RMSE_train[2] <- rmse2

sm3 <-summary(model_lm3)
rmse3 <- sqrt(mean(sm3$residuals^2))
RMSE_train[3] <- rmse3

sm4 <-summary(model_lm4)
rmse4 <- sqrt(mean(sm4$residuals^2))
RMSE_train[4] <- rmse4

sm5 <-summary(model_lm5)
rmse5 <- sqrt(mean(sm5$residuals^2))
RMSE_train[5] <- rmse5

sm6 <-summary(model_lm6)
rmse6 <- sqrt(mean(sm6$residuals^2))
RMSE_train[6] <- rmse6

sm7 <-summary(model_lm7)
rmse7 <- sqrt(mean(sm7$residuals^2))
RMSE_train[7] <- rmse7

prediction1 <- model_lm1 %>% 
    broom::augment(newdata=credit_test) 

rmse1_test <- sqrt(mean((prediction1$Balance-prediction1$.fitted)^2))
RMSE_test[1] <- rmse1_test

prediction2 <-model_lm2 %>% 
    broom::augment(newdata=credit_test) 

rmse2_test <- sqrt(mean((prediction2$Balance-prediction2$.fitted)^2))
RMSE_test[2] <- rmse2_test

prediction3 <- model_lm3 %>% 
    broom::augment(newdata=credit_test)

rmse3_test <- sqrt(mean((prediction3$Balance-prediction3$.fitted)^2))
RMSE_test[3] <- rmse3_test

prediction4 <- model_lm4 %>% 
    broom::augment(newdata=credit_test)

rmse4_test <- sqrt(mean((prediction4$Balance-prediction4$.fitted)^2))
RMSE_test[4] <- rmse4_test

prediction5 <- model_lm5 %>% 
    broom::augment(newdata=credit_test)

rmse5_test <- sqrt(mean((prediction5$Balance-prediction5$.fitted)^2))
RMSE_test[5] <- rmse5_test

prediction6 <-model_lm6 %>% 
    broom::augment(newdata=credit_test)

rmse6_test <- sqrt(mean((prediction6$Balance-prediction6$.fitted)^2))
RMSE_test[6] <- rmse6_test

prediction7 <- model_lm7 %>% 
    broom::augment(newdata=credit_test)

rmse7_test <- sqrt(mean((prediction7$Balance-prediction7$.fitted)^2))
RMSE_test[7] <- rmse7_test

# Save results in a data frame. Note this data frame is in wide format.
results <- data_frame(
  num_coefficients = 1:7,
  RMSE_train,
  RMSE_test
) 

# Some cleaning of results
results <- results %>% 
  # More intuitive names:
  rename(
    `Training data` = RMSE_train,
    `Test data` = RMSE_test
  ) %>% 
  # Convert results data frame to "tidy" data format i.e. long format, so that we
  # can ggplot it
  gather(type, RMSE, -num_coefficients)

ggplot(results, aes(x=num_coefficients, y=RMSE, col=type)) +
  geom_line() + 
  labs(x="# of coefficients", y="RMSE", col="Data used to evaluate \nperformance of fitted model")
```


# Interpret the graph

Compare and contrast the two curves and hypothesize as to the root cause of any differences.

As the number of coefficients increase, the RMSE of the training set will continually decrease, as we will be continually overfitting the data. When we apply the models to the Test set, the RMSE will at a certain point start to increase because the overfitting will start to include too much of the "noise" of the dataset compared to the signal.


# Bonus

Repeat the whole process, but let `credit_train` be a random sample of size 380
from `credit` instead of 20. Now compare and contrast this graph with the
one above and hypothesize as to the root cause of any differences.

Code ommitted because it is nearly identical to above code.

```{r, echo=FALSE}
credit_train_b <- credit %>% 
  sample_n(380)
credit_test_b <- credit %>% 
  anti_join(credit_train_b, by="ID")
```

```{r, echo=FALSE}
RMSE_train_b <- runif(n=7)
RMSE_test_b <- runif(n=7)
```


```{r, warning = FALSE, echo = FALSE}
model_lm1_b <- lm(model1_formula, data=credit_train_b)
model_lm2_b <- lm(model2_formula, data=credit_train_b)
model_lm3_b <- lm(model3_formula, data=credit_train_b)
model_lm4_b <- lm(model4_formula, data=credit_train_b)
model_lm5_b <- lm(model5_formula, data=credit_train_b)
model_lm6_b <- lm(model6_formula, data=credit_train_b)
model_lm7_b <- lm(model7_formula, data=credit_train_b)

sm1b <-summary(model_lm1_b)
rmse1b <- sqrt(mean(sm1b$residuals^2))
RMSE_train_b[1] <- rmse1b

sm2b <-summary(model_lm2_b)
rmse2b <- sqrt(mean(sm2b$residuals^2))
RMSE_train_b[2] <- rmse2b

sm3b <-summary(model_lm3_b)
rmse3b <- sqrt(mean(sm3b$residuals^2))
RMSE_train_b[3] <- rmse3b

sm4b <-summary(model_lm4_b)
rmse4b <- sqrt(mean(sm4b$residuals^2))
RMSE_train_b[4] <- rmse4b

sm5b <-summary(model_lm5_b)
rmse5b <- sqrt(mean(sm5b$residuals^2))
RMSE_train_b[5] <- rmse5b

sm6b <-summary(model_lm6_b)
rmse6b <- sqrt(mean(sm6b$residuals^2))
RMSE_train_b[6] <- rmse6b

sm7b <-summary(model_lm7_b)
rmse7b <- sqrt(mean(sm7b$residuals^2))
RMSE_train_b[7] <- rmse7b

prediction1_b <- model_lm1_b %>% 
    broom::augment(newdata=credit_test_b) 

rmse1_test_b <- sqrt(mean((prediction1_b$Balance-prediction1_b$.fitted)^2))
RMSE_test_b[1] <- rmse1_test_b

prediction2_b <-model_lm2_b %>% 
    broom::augment(newdata=credit_test_b) 

rmse2_test_b <- sqrt(mean((prediction2_b$Balance-prediction2_b$.fitted)^2))
RMSE_test_b[2] <- rmse2_test_b

prediction3_b <- model_lm3_b %>% 
    broom::augment(newdata=credit_test_b)

rmse3_test_b <- sqrt(mean((prediction3_b$Balance-prediction3_b$.fitted)^2))
RMSE_test_b[3] <- rmse3_test_b

prediction4_b <- model_lm4_b %>% 
    broom::augment(newdata=credit_test_b)

rmse4_test_b <- sqrt(mean((prediction4_b$Balance-prediction4_b$.fitted)^2))
RMSE_test_b[4] <- rmse4_test_b

prediction5_b <- model_lm5_b %>% 
    broom::augment(newdata=credit_test_b)

rmse5_test_b <- sqrt(mean((prediction5_b$Balance-prediction5_b$.fitted)^2))
RMSE_test_b[5] <- rmse5_test_b

prediction6_b <-model_lm6_b %>% 
    broom::augment(newdata=credit_test_b)

rmse6_test_b <- sqrt(mean((prediction6_b$Balance-prediction6_b$.fitted)^2))
RMSE_test_b[6] <- rmse6_test_b

prediction7_b <- model_lm7_b %>% 
    broom::augment(newdata=credit_test_b)

rmse7_test_b <- sqrt(mean((prediction7_b$Balance-prediction7_b$.fitted)^2))
RMSE_test_b[7] <- rmse7_test_b

# Save results in a data frame. Note this data frame is in wide format.
results_b <- data_frame(
  num_coefficients = 1:7,
  RMSE_train_b,
  RMSE_test_b
) 

# Some cleaning of results
results_b <- results_b %>% 
  # More intuitive names:
  rename(
    `Training data_b` = RMSE_train_b,
    `Test data_b` = RMSE_test_b
  ) %>% 
  # Convert results data frame to "tidy" data format i.e. long format, so that we
  # can ggplot it
  gather(type, RMSE, -num_coefficients)

ggplot(results_b, aes(x=num_coefficients, y=RMSE, col=type)) +
  geom_line() + 
  labs(x="# of coefficients", y="RMSE", col="Data used to evaluate \nperformance of fitted model")
```

Because the training set is so much larger compared to the test set, the model is actually underfitted. 
